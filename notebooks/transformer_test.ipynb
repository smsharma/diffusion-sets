{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5df3992d-b168-4bbb-9c74-1ad740523a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models.train_utils import param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "75d48827-f25b-4436-a2bb-9656d106ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.linen.attention import dot_product_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2a961885-45d3-4eb3-b936-0190ac61681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    n_heads: int\n",
    "    d_model: int\n",
    "    d_mlp: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y, mask=None):\n",
    "\n",
    "        mask = None if mask is None else mask[..., None, :, :]\n",
    "\n",
    "        # Multi-head attention\n",
    "        x_mhsa = nn.LayerNorm()(x)\n",
    "        x_mhsa = nn.MultiHeadDotProductAttention(num_heads=self.n_heads, kernel_init=nn.initializers.xavier_uniform(), bias_init=nn.initializers.zeros)(x, y, mask)\n",
    "\n",
    "        # Add into residual stream\n",
    "        x += x_mhsa\n",
    "\n",
    "        # MLP\n",
    "        x_mlp = nn.LayerNorm()(x)\n",
    "        x_mlp = nn.gelu(nn.Dense(self.d_mlp)(x))\n",
    "        x_mlp = nn.Dense(self.d_model)(x_mlp)\n",
    "\n",
    "        # Add into residual stream and norm\n",
    "        x += x_mlp\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PoolingByMultiHeadAttention(nn.Module):\n",
    "    n_seed_vectors: int\n",
    "    n_heads: int\n",
    "    d_model: int\n",
    "    d_mlp: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, z, mask=None):\n",
    "        seed_vectors = self.param(\"seed_vectors\", nn.linear.default_embed_init, (self.n_seed_vectors, z.shape[-1]))\n",
    "        seed_vectors = jnp.broadcast_to(seed_vectors, z.shape[:-2] + seed_vectors.shape)\n",
    "        mask = None if mask is None else mask[..., None, :]\n",
    "        return MultiHeadAttentionBlock(n_heads=n_heads, d_model=self.d_model, d_mlp=d_mlp)(seed_vectors, z, mask)\n",
    "\n",
    "\n",
    "class TransformerFlax(nn.Module):\n",
    "    \"\"\"Simple decoder-only transformer for set modeling.\n",
    "    Attributes:\n",
    "      n_input: The number of input (and output) features.\n",
    "      d_model: The dimension of the model embedding space.\n",
    "      d_mlp: The dimension of the multi-layer perceptron (MLP) used in the feed-forward network.\n",
    "      n_layers: Number of transformer layers.\n",
    "      n_heads: The number of attention heads.\n",
    "      induced_attention: Whether to use induced attention.\n",
    "      n_inducing_points: The number of inducing points for induced attention.\n",
    "    \"\"\"\n",
    "\n",
    "    n_input: int\n",
    "    d_model: int = 128\n",
    "    d_mlp: int = 512\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    induced_attention: bool = False\n",
    "    n_inducing_points: int = 32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.ndarray, conditioning: jnp.ndarray = None, mask=None):\n",
    "\n",
    "        # Input embedding\n",
    "        x = nn.Dense(int(self.d_model))(x)  # (batch, seq_len, d_model)\n",
    "\n",
    "        # Add conditioning\n",
    "        if conditioning is not None:\n",
    "            conditioning = nn.Dense(int(self.d_model))(conditioning)  # (batch, d_model)\n",
    "            x += conditioning[:, None, :]  # (batch, seq_len, d_model)\n",
    "\n",
    "        # Transformer layers\n",
    "        for _ in range(self.n_layers):\n",
    "\n",
    "            if not self.induced_attention:\n",
    "                mask_attn = None if mask is None else mask[..., None] * mask[..., None, :]\n",
    "                x = MultiHeadAttentionBlock(n_heads=self.n_heads, d_model=self.d_model, d_mlp=self.d_mlp)(x, x, mask_attn)\n",
    "            else:\n",
    "                h = PoolingByMultiHeadAttention(self.n_inducing_points, self.n_heads, d_model=self.d_model, d_mlp=self.d_mlp)(x, mask)\n",
    "                mask_attn = None if mask is None else mask[..., None]\n",
    "                x = MultiHeadAttentionBlock(n_heads=self.n_heads, d_model=self.d_model, d_mlp=self.d_mlp)(x, h, mask_attn)\n",
    "\n",
    "        # Final LayerNorm\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Unembed; zero init kernel to propagate zero residual initially before training\n",
    "        x = nn.Dense(self.n_input, kernel_init=jax.nn.initializers.zeros)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "import math\n",
    "import importlib\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"Compute scaled dot-product masked attention.\"\"\"\n",
    "    d_k = q.shape[-1]\n",
    "    attn_logits = jnp.matmul(q, jnp.swapaxes(k, -2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = jnp.where(mask[:, None, None, :] == 0, -9e15, attn_logits)\n",
    "    attention = nn.softmax(attn_logits, axis=-1)\n",
    "    values = jnp.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"Simple decoder-only transformer for set modeling.\n",
    "    Attributes:\n",
    "      n_input: The number of input (and output) features.\n",
    "      d_model: The dimension of the model embedding space.\n",
    "      d_mlp: The dimension of the multi-layer perceptron (MLP) used in the feed-forward network.\n",
    "      n_layers: Number of transformer layers.\n",
    "      n_heads: The number of attention heads.\n",
    "      flash_attention: Flag that indicates whether to use flash attention or not.\n",
    "    \"\"\"\n",
    "\n",
    "    n_input: int\n",
    "    d_model: int = 128\n",
    "    d_mlp: int = 512\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    flash_attention: bool = False\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.ndarray, conditioning: jnp.ndarray = None, mask=None):\n",
    "\n",
    "        # Sequence length\n",
    "        batch, seq_length = x.shape[0], x.shape[1]\n",
    "\n",
    "        # Input embedding\n",
    "        x = nn.Dense(int(self.d_model))(x)  # (batch, seq_len, d_model)\n",
    "        if conditioning is not None:\n",
    "            conditioning = nn.Dense(int(self.d_model))(conditioning)  # (batch, d_model)\n",
    "            x += conditioning[:, None, :]  # (batch, seq_len, d_model)\n",
    "\n",
    "        # Mask according to set cardinality\n",
    "        mask_attn = jnp.ones((batch, seq_length)) if mask is None else mask\n",
    "\n",
    "        # Transformer layers\n",
    "        for _ in range(self.n_layers):\n",
    "            \n",
    "            # LayerNorm each time residual stream is written onto\n",
    "            x1 = nn.LayerNorm()(x)\n",
    "\n",
    "            # Get qkv projections\n",
    "            qkv = nn.Dense(3 * self.d_model, kernel_init=nn.initializers.xavier_uniform(), bias_init=nn.initializers.zeros)(x1)\n",
    "\n",
    "            # Project out separate q, k, v\n",
    "            qkv = rearrange(qkv, \"batch seq_length (n_heads d_heads_3) -> batch n_heads seq_length d_heads_3\", n_heads=self.n_heads)\n",
    "            q, k, v = jnp.split(qkv, 3, axis=-1)  # (batch, n_heads, seq_length, d_heads)\n",
    "\n",
    "            # Compute attention\n",
    "            x_heads, _ = scaled_dot_product_attention(q, k, v, mask=mask_attn)  # (batch, n_heads, seq_length, d_heads)\n",
    "            x_heads = rearrange(x_heads, \"batch n_heads seq_length d_heads -> batch seq_length (n_heads d_heads)\")\n",
    "\n",
    "            # x_heads = dot_product_attention(q[..., None], k[..., None], v[..., None], mask=None)[..., 0]\n",
    "            # x_heads = rearrange(x_heads, \"batch n_heads seq_length d_heads -> batch seq_length (n_heads d_heads)\")\n",
    "\n",
    "            # Output\n",
    "            x_heads = nn.Dense(self.d_model, kernel_init=nn.initializers.xavier_uniform(), bias_init=nn.initializers.zeros)(x_heads)\n",
    "\n",
    "            x += x_heads  # Write residual stream\n",
    "\n",
    "            # LayerNorm\n",
    "            x2 = nn.LayerNorm()(x)\n",
    "\n",
    "            # MLP\n",
    "            x2 = nn.Dense(self.d_mlp)(x2)\n",
    "            x2 = jax.nn.gelu(x2)\n",
    "            x2 = nn.Dense(self.d_model)(x2)\n",
    "\n",
    "            x += x2  # Write residual stream\n",
    "\n",
    "        # Final LayerNorm\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Unembed\n",
    "        x = nn.Dense(self.n_input, kernel_init=jax.nn.initializers.zeros)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cbc093c-20ea-4765-8aed-e0db5a222156",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 64\n",
    "d_model = 256\n",
    "d_mlp = 1024\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "x = jax.random.normal(rng, (32, 16, n_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5cca3ab4-f657-4f81-a5fc-39c1b44ddb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clu import parameter_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4453a82c-7e8d-404a-938b-f5b870ab11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(n_input=n_input, d_model=d_model, d_mlp=d_mlp, n_layers=n_layers, n_heads=n_heads)\n",
    "_, params = transformer.init_with_output({\"params\": rng}, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "212ba039-09ce-4e74-97ba-f2a2510479e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------------+---------+-----------+--------+\n",
      "| Name                     | Shape       | Size    | Mean      | Std    |\n",
      "+--------------------------+-------------+---------+-----------+--------+\n",
      "| params/Dense_0/bias      | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/Dense_0/kernel    | (64, 256)   | 16,384  | 0.000496  | 0.126  |\n",
      "| params/Dense_1/bias      | (768,)      | 768     | 0.0       | 0.0    |\n",
      "| params/Dense_1/kernel    | (256, 768)  | 196,608 | 0.000112  | 0.0443 |\n",
      "| params/Dense_2/bias      | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/Dense_2/kernel    | (256, 256)  | 65,536  | 0.000391  | 0.0625 |\n",
      "| params/Dense_3/bias      | (1024,)     | 1,024   | 0.0       | 0.0    |\n",
      "| params/Dense_3/kernel    | (256, 1024) | 262,144 | 2.5e-05   | 0.0624 |\n",
      "| params/Dense_4/bias      | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/Dense_4/kernel    | (1024, 256) | 262,144 | 8.45e-06  | 0.0313 |\n",
      "| params/Dense_5/bias      | (768,)      | 768     | 0.0       | 0.0    |\n",
      "| params/Dense_5/kernel    | (256, 768)  | 196,608 | -7.15e-05 | 0.0442 |\n",
      "| params/Dense_6/bias      | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/Dense_6/kernel    | (256, 256)  | 65,536  | 4.74e-05  | 0.0626 |\n",
      "| params/Dense_7/bias      | (1024,)     | 1,024   | 0.0       | 0.0    |\n",
      "| params/Dense_7/kernel    | (256, 1024) | 262,144 | 1.98e-06  | 0.0626 |\n",
      "| params/Dense_8/bias      | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/Dense_8/kernel    | (1024, 256) | 262,144 | -3.45e-05 | 0.0313 |\n",
      "| params/Dense_9/bias      | (64,)       | 64      | 0.0       | 0.0    |\n",
      "| params/Dense_9/kernel    | (256, 64)   | 16,384  | 0.0       | 0.0    |\n",
      "| params/LayerNorm_0/bias  | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/LayerNorm_0/scale | (256,)      | 256     | 1.0       | 0.0    |\n",
      "| params/LayerNorm_1/bias  | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/LayerNorm_1/scale | (256,)      | 256     | 1.0       | 0.0    |\n",
      "| params/LayerNorm_2/bias  | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/LayerNorm_2/scale | (256,)      | 256     | 1.0       | 0.0    |\n",
      "| params/LayerNorm_3/bias  | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/LayerNorm_3/scale | (256,)      | 256     | 1.0       | 0.0    |\n",
      "| params/LayerNorm_4/bias  | (256,)      | 256     | 0.0       | 0.0    |\n",
      "| params/LayerNorm_4/scale | (256,)      | 256     | 1.0       | 0.0    |\n",
      "+--------------------------+-------------+---------+-----------+--------+\n",
      "Total: 1,613,120\n"
     ]
    }
   ],
   "source": [
    "print(parameter_overview.get_parameter_overview(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8f8ab32-012e-49c0-9794-ae41f3ccc772",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerFlax(n_input=n_input, d_model=d_model, d_mlp=d_mlp, n_layers=n_layers, n_heads=n_heads)\n",
    "_, params = transformer.init_with_output({\"params\": rng}, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a8b3b1f7-0600-46e2-beac-2d5e5a595fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+---------------+---------+-----------+--------+\n",
      "| Name                                                                         | Shape         | Size    | Mean      | Std    |\n",
      "+------------------------------------------------------------------------------+---------------+---------+-----------+--------+\n",
      "| params/Dense_0/bias                                                          | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/Dense_0/kernel                                                        | (64, 256)     | 16,384  | 0.000496  | 0.126  |\n",
      "| params/Dense_1/bias                                                          | (64,)         | 64      | 0.0       | 0.0    |\n",
      "| params/Dense_1/kernel                                                        | (256, 64)     | 16,384  | 0.0       | 0.0    |\n",
      "| params/LayerNorm_0/bias                                                      | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/LayerNorm_0/scale                                                     | (256,)        | 256     | 1.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/Dense_0/bias                                | (1024,)       | 1,024   | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/Dense_0/kernel                              | (256, 1024)   | 262,144 | -8.75e-06 | 0.0626 |\n",
      "| params/MultiHeadAttentionBlock_0/Dense_1/bias                                | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/Dense_1/kernel                              | (1024, 256)   | 262,144 | 4.1e-05   | 0.0312 |\n",
      "| params/MultiHeadAttentionBlock_0/LayerNorm_0/bias                            | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/LayerNorm_0/scale                           | (256,)        | 256     | 1.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/LayerNorm_1/bias                            | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/LayerNorm_1/scale                           | (256,)        | 256     | 1.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/key/bias     | (2, 128)      | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/key/kernel   | (256, 2, 128) | 65,536  | 0.000502  | 0.0626 |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/out/bias     | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/out/kernel   | (2, 128, 256) | 65,536  | 0.000212  | 0.0625 |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/query/bias   | (2, 128)      | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/query/kernel | (256, 2, 128) | 65,536  | 0.000138  | 0.0626 |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/value/bias   | (2, 128)      | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_0/MultiHeadDotProductAttention_0/value/kernel | (256, 2, 128) | 65,536  | -0.000121 | 0.0624 |\n",
      "| params/MultiHeadAttentionBlock_1/Dense_0/bias                                | (1024,)       | 1,024   | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/Dense_0/kernel                              | (256, 1024)   | 262,144 | -0.000174 | 0.0625 |\n",
      "| params/MultiHeadAttentionBlock_1/Dense_1/bias                                | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/Dense_1/kernel                              | (1024, 256)   | 262,144 | 3.83e-05  | 0.0313 |\n",
      "| params/MultiHeadAttentionBlock_1/LayerNorm_0/bias                            | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/LayerNorm_0/scale                           | (256,)        | 256     | 1.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/LayerNorm_1/bias                            | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/LayerNorm_1/scale                           | (256,)        | 256     | 1.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/key/bias     | (2, 128)      | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/key/kernel   | (256, 2, 128) | 65,536  | -7.56e-05 | 0.0623 |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/out/bias     | (256,)        | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/out/kernel   | (2, 128, 256) | 65,536  | 0.000592  | 0.0624 |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/query/bias   | (2, 128)      | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/query/kernel | (256, 2, 128) | 65,536  | 5.41e-05  | 0.0624 |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/value/bias   | (2, 128)      | 256     | 0.0       | 0.0    |\n",
      "| params/MultiHeadAttentionBlock_1/MultiHeadDotProductAttention_0/value/kernel | (256, 2, 128) | 65,536  | 0.000179  | 0.0626 |\n",
      "+------------------------------------------------------------------------------+---------------+---------+-----------+--------+\n",
      "Total: 1,613,120\n"
     ]
    }
   ],
   "source": [
    "print(parameter_overview.get_parameter_overview(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f122ef8-a71c-4fc7-9355-3c120c78ada8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4825c-9e2a-48d8-a816-4c1b659360d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde51cf-d9fd-4184-91b3-f7b7c18f4230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
