{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "# ! pip install tensorflow-probability\n",
    "# ! pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pandas yaml tensorflow tensorflow-probability ml-collections jraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import optax\n",
    "import flax\n",
    "from flax.core import FrozenDict\n",
    "from flax.training import train_state, checkpoints\n",
    "from ml_collections.config_dict import ConfigDict\n",
    "import numpy as vnp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure TF does not see GPU and grab all GPU memory\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "replicate = flax.jax_utils.replicate\n",
    "unreplicate = flax.jax_utils.unreplicate\n",
    "\n",
    "from models.diffusion import VariationalDiffusionModel\n",
    "from models.diffusion_utils import loss_vdm, sigma2, generate\n",
    "from models.train_utils import create_input_iter, param_count, train_step\n",
    "from datasets import load_data\n",
    "\n",
    "EPS = 1e-7\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/n/holyscratch01/iaifi_lab/ccuesta/data_for_sid/\"\n",
    "\n",
    "## Carol's runs\n",
    "# logging_dir = \"/n/holyscratch01/iaifi_lab/ccuesta/checkpoints/\"\n",
    "\n",
    "# run_name = \"blooming-puddle-230\"  # Has weird likelihoods\n",
    "# run_name = \"chocolate-cloud-122\"  # The one in the paper\n",
    "# run_name = \"silver-breeze-231\"  # Only rotations\n",
    "# run_name = \"hopeful-bush-231\"  # Only translations\n",
    "\n",
    "## My new runs\n",
    "logging_dir = \"/n/holystore01/LABS/iaifi_lab/Users/smsharma/set-diffuser/logging/cosmology-augmentations-guidance/\"\n",
    "# logging_dir = \"/n/holystore01/LABS/iaifi_lab/Users/smsharma/set-diffuser/logging/cosmology-augmentations/\"\n",
    "# run_name = \"efficient-firefly-111\"  # No translations or rotations\n",
    "# run_name = \"worldly-voice-112\"  # Only translations\n",
    "# run_name = \"stilted-oath-118\" # Both; longer run\n",
    "# run_name = \"blooming-waterfall-120\"  # Different config; larger batch size etc\n",
    "# run_name = \"solar-pond-123\"  # k=100, batch size 16\n",
    "# run_name = \"treasured-resonance-125\"\n",
    "# run_name = \"peach-gorge-130\"\n",
    "# run_name = \"glowing-rain-139\"  # Run with unconditional dropout\n",
    "run_name = \"toasty-dream-140\"  # Run without unconditional dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cluster run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"{}/{}/config.yaml\".format(logging_dir, run_name)\n",
    "\n",
    "with open(config_file, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "config = ConfigDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_ds, norm_dict = load_data(\n",
    "        \"nbody\",\n",
    "        3,\n",
    "        5000,\n",
    "        8,\n",
    "        42,\n",
    "        shuffle=True,\n",
    "        split=\"train\",\n",
    "    )\n",
    "\n",
    "batches = create_input_iter(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, conditioning, mask = next(batches)\n",
    "x = x[0]\n",
    "conditioning = conditioning[0]\n",
    "mask = mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion model\n",
    "x_mean = tuple(map(float, norm_dict[\"mean\"]))\n",
    "x_std = tuple(map(float, norm_dict[\"std\"]))\n",
    "config.data.apply_pbcs = False\n",
    "box_size = config.data.box_size if config.data.apply_pbcs else None\n",
    "unit_cell = tuple(map(tuple, config.data.unit_cell)) if config.data.apply_pbcs else None\n",
    "\n",
    "norm_dict_input = FrozenDict(\n",
    "    {\n",
    "        \"x_mean\": x_mean,\n",
    "        \"x_std\": x_std,\n",
    "        \"box_size\": box_size,\n",
    "        \"unit_cell\": unit_cell,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 devices visible\n",
      "Params: 535,101\n"
     ]
    }
   ],
   "source": [
    "print(\"{} devices visible\".format(jax.device_count()))\n",
    "\n",
    "# Score and (optional) encoder model configs\n",
    "score_dict = FrozenDict(config.score)\n",
    "encoder_dict = FrozenDict(config.encoder)\n",
    "decoder_dict = FrozenDict(config.decoder)\n",
    "\n",
    "# Diffusion model\n",
    "vdm = VariationalDiffusionModel(\n",
    "        d_feature=config.data.n_features,\n",
    "        timesteps=config.vdm.timesteps,\n",
    "        noise_schedule=config.vdm.noise_schedule,\n",
    "        noise_scale=config.vdm.noise_scale,\n",
    "        d_t_embedding=config.vdm.d_t_embedding,\n",
    "        gamma_min=config.vdm.gamma_min,\n",
    "        gamma_max=config.vdm.gamma_max,\n",
    "        score=config.score.score,\n",
    "        score_dict=score_dict,\n",
    "        embed_context=config.vdm.embed_context,\n",
    "        d_context_embedding=config.vdm.d_context_embedding,\n",
    "        n_classes=config.vdm.n_classes,\n",
    "        use_encdec=config.vdm.use_encdec,\n",
    "        encoder_dict=encoder_dict,\n",
    "        decoder_dict=decoder_dict,\n",
    "        norm_dict=norm_dict_input,\n",
    ")\n",
    "\n",
    "# Pass a test batch through to initialize model\n",
    "x_batch, conditioning_batch, mask_batch = next(batches)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "_, params = vdm.init_with_output({\"sample\": rng, \"params\": rng}, x_batch[0], conditioning_batch[0], mask_batch[0])\n",
    "\n",
    "print(f\"Params: {param_count(params):,}\")\n",
    "\n",
    "# Training config and state\n",
    "schedule = optax.warmup_cosine_decay_schedule(init_value=0.0, peak_value=config.optim.learning_rate, warmup_steps=config.training.warmup_steps, decay_steps=config.training.n_train_steps)\n",
    "tx = optax.adamw(learning_rate=schedule, weight_decay=config.optim.weight_decay)\n",
    "state = train_state.TrainState.create(apply_fn=vdm.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_dir = \"{}/{}/\".format(logging_dir, run_name)  # Load SLURM run\n",
    "# restored_state = checkpoints.restore_checkpoint(ckpt_dir=ckpt_dir, target=state)\n",
    "\n",
    "# if state is restored_state:\n",
    "#     raise FileNotFoundError(f\"Did not load checkpoint correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_loss(params, x, cond, mask):\n",
    "    l1, l2, l3 = vdm.apply(params, x, cond, mask, rngs={\"sample\": rng, \"params\": rng})\n",
    "    return l1.sum() + l2.sum() + l3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_loss(x_batch[0][:8], conditioning_batch[0][:8], mask_batch[0][:8])\n",
    "\n",
    "# with jax.profiler.trace(\"./profile/jax-trace\", create_perfetto_link=False, create_perfetto_trace=True):\n",
    "#   get_loss(x_batch[0][:8], conditioning_batch[0][:8], mask_batch[0][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 5000\n",
    "n_batch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 18:06:38.476184: E external/xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %fusion.367 = (pred[4,250000]{1,0}, s32[4,250000,2]{2,1,0}) fusion(s32[2]{0} %constant.1365, s32[4,250000]{1,0} %constant.2606, s32[4,125000]{1,0} %constant.2631, s32[4,125000]{1,0} %constant.2632), kind=kInput, calls=%fused_computation.367, metadata={op_name=\"jit(get_loss)/jit(main)/VariationalDiffusionModel/VariationalDiffusionModel.diffusion_loss/score_model/vmap(GraphConvNet_0)/jit(_take)/reduce_and[axes=(2,)]\" source_file=\"/n/home11/smsharma/.local/lib/python3.10/site-packages/jraph/_src/models.py\" source_line=178}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2023-08-23 18:06:41.820492: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.347296304s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %fusion.367 = (pred[4,250000]{1,0}, s32[4,250000,2]{2,1,0}) fusion(s32[2]{0} %constant.1365, s32[4,250000]{1,0} %constant.2606, s32[4,125000]{1,0} %constant.2631, s32[4,125000]{1,0} %constant.2632), kind=kInput, calls=%fused_computation.367, metadata={op_name=\"jit(get_loss)/jit(main)/VariationalDiffusionModel/VariationalDiffusionModel.diffusion_loss/score_model/vmap(GraphConvNet_0)/jit(_take)/reduce_and[axes=(2,)]\" source_file=\"/n/home11/smsharma/.local/lib/python3.10/site-packages/jraph/_src/models.py\" source_line=178}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 ms ± 29.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jax.value_and_grad(get_loss)(params, x_batch[0][:n_batch, :n_nodes], conditioning_batch[0][:n_batch, :n_nodes], mask_batch[0][:n_batch, :n_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.513513513513514"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 / 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.graph_utils import nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "sources, targets, dist = jax.vmap(nearest_neighbors, in_axes=(0, None, 0))(x_batch[0][:n_batch, :n_nodes], 50, mask_batch[0][:n_batch, :n_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[   0,    0,    0, ..., 4999, 4999, 4999],\n",
       "        [   0,    0,    0, ..., 4999, 4999, 4999],\n",
       "        [   0,    0,    0, ..., 4999, 4999, 4999],\n",
       "        [   0,    0,    0, ..., 4999, 4999, 4999]], dtype=int32),\n",
       " Array([[   0,  193,  194, ..., 4102,   67, 4855],\n",
       "        [   0,  530, 3426, ...,  686, 1499, 2872],\n",
       "        [   0, 4500, 3226, ..., 3098, 3821, 4536],\n",
       "        [   0, 4079,  685, ..., 4322,  384, 3414]], dtype=int32),\n",
       " Array([[0.        , 0.00088743, 0.01018956, ..., 0.17113404, 0.17649578,\n",
       "         0.1828176 ],\n",
       "        [0.        , 0.03095622, 0.03634575, ..., 0.18830384, 0.19302878,\n",
       "         0.20054212],\n",
       "        [0.        , 0.03018067, 0.03622621, ..., 0.17344593, 0.17392701,\n",
       "         0.17541279],\n",
       "        [0.        , 0.00714167, 0.01390084, ..., 0.1959911 , 0.1978073 ,\n",
       "         0.19785741]], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources, targets, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources, targets, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss(x_batch[0][:8], conditioning_batch[0][:8], mask_batch[0][:8])\n",
    "\n",
    "jax.profiler.start_trace(\"./profile/tensorboard\")\n",
    "\n",
    "get_loss(x_batch[0][:8], conditioning_batch[0][:8], mask_batch[0][:8])\n",
    "\n",
    "jax.profiler.stop_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdm.apply(restored_state.params, x, cond, mask, rngs={\"sample\": rng, \"params\": rng})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
