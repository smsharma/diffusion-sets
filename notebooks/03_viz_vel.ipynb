{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "# ! pip install tensorflow-probability\n",
    "# ! pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pandas yaml tensorflow tensorflow-probability ml-collections jraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import optax\n",
    "import flax\n",
    "from flax.core import FrozenDict\n",
    "from flax.training import train_state, checkpoints\n",
    "from ml_collections.config_dict import ConfigDict\n",
    "import numpy as vnp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure TF does not see GPU and grab all GPU memory\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "replicate = flax.jax_utils.replicate\n",
    "unreplicate = flax.jax_utils.unreplicate\n",
    "\n",
    "from models.diffusion import VariationalDiffusionModel\n",
    "from models.diffusion_utils import loss_vdm, sigma2, generate\n",
    "from models.train_utils import create_input_iter, param_count, train_step\n",
    "from datasets import load_data\n",
    "\n",
    "EPS = 1e-7\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap('viridis_r')\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "\n",
    "from plot_params import params\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "\n",
    "pylab.rcParams.update(params)\n",
    "cols_default = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "import logging\n",
    "import matplotlib\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/n/holyscratch01/iaifi_lab/ccuesta/data_for_sid/\"\n",
    "\n",
    "## My new runs\n",
    "logging_dir = \"/n/holystore01/LABS/iaifi_lab/Lab/set-diffuser-checkpoints/cosmology/\"\n",
    "run_name = \"divine-breeze-139\"  # GNN\n",
    "run_name = \"magical-goosebump-109\"  # Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from datasets import get_nbody_data\n",
    "x, _, conditioning, norm_dict = get_nbody_data(n_features=7, n_particles=5000, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cluster run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"{}/{}/config.yaml\".format(logging_dir, run_name)\n",
    "\n",
    "with open(config_file, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "config = ConfigDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_ds, norm_dict = load_data(\n",
    "        config.data.dataset,\n",
    "        config.data.n_features,\n",
    "        config.data.n_particles,\n",
    "        32,\n",
    "        config.seed,\n",
    "        shuffle=True,\n",
    "        split=\"test\",\n",
    "        #**config.data.kwargs,\n",
    "    )\n",
    "\n",
    "batches = create_input_iter(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_augmentations: true\n",
       "add_rotations: true\n",
       "add_translations: true\n",
       "box_size: 1000.0\n",
       "conditioning_parameters:\n",
       "- Omega_m\n",
       "- sigma_8\n",
       "dataset: nbody\n",
       "kwargs: {}\n",
       "n_features: 7\n",
       "n_particles: 5000\n",
       "n_pos_features: 3\n",
       "simulation_set: lhc"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_size: 16\n",
       "eval_every_steps: 5000\n",
       "half_precision: false\n",
       "log_every_steps: 100\n",
       "n_train_steps: 301000\n",
       "p_uncond: 0.0\n",
       "save_every_steps: 5000\n",
       "unconditional_dropout: false\n",
       "warmup_steps: 5000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, conditioning, mask = next(batches)\n",
    "x = x.reshape(-1, config.data.n_particles, config.data.n_features)\n",
    "conditioning = conditioning.reshape(-1, 2)\n",
    "mask = mask.reshape(-1, config.data.n_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion model\n",
    "x_mean = tuple(map(float, norm_dict[\"mean\"]))\n",
    "x_std = tuple(map(float, norm_dict[\"std\"]))\n",
    "config.data.apply_pbcs = False\n",
    "box_size = config.data.box_size #if config.data.apply_pbcs else None\n",
    "unit_cell = tuple(map(tuple, config.data.unit_cell)) if config.data.apply_pbcs else None\n",
    "\n",
    "norm_dict_input = FrozenDict(\n",
    "    {\n",
    "        \"x_mean\": x_mean,\n",
    "        \"x_std\": x_std,\n",
    "        \"box_size\": box_size,\n",
    "        \"unit_cell\": unit_cell,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 devices visible\n",
      "Params: 4,776,281\n"
     ]
    }
   ],
   "source": [
    "print(\"{} devices visible\".format(jax.device_count()))\n",
    "\n",
    "# Score and (optional) encoder model configs\n",
    "score_dict = FrozenDict(config.score)\n",
    "encoder_dict = FrozenDict(config.encoder)\n",
    "decoder_dict = FrozenDict(config.decoder)\n",
    "\n",
    "# Diffusion model\n",
    "vdm = VariationalDiffusionModel(\n",
    "        d_feature=config.data.n_features,\n",
    "        timesteps=config.vdm.timesteps,\n",
    "        noise_schedule=config.vdm.noise_schedule,\n",
    "        # noise_schedule=\"linear\",\n",
    "        noise_scale=config.vdm.noise_scale,\n",
    "        d_t_embedding=config.vdm.d_t_embedding,\n",
    "        gamma_min=config.vdm.gamma_min,\n",
    "        gamma_max=config.vdm.gamma_max,\n",
    "        score=config.score.score,\n",
    "        score_dict=score_dict,\n",
    "        embed_context=config.vdm.embed_context,\n",
    "        d_context_embedding=config.vdm.d_context_embedding,\n",
    "        n_classes=config.vdm.n_classes,\n",
    "        use_encdec=config.vdm.use_encdec,\n",
    "        encoder_dict=encoder_dict,\n",
    "        decoder_dict=decoder_dict,\n",
    "        norm_dict=norm_dict_input,\n",
    ")\n",
    "\n",
    "# Pass a test batch through to initialize model\n",
    "x_batch, conditioning_batch, mask_batch = next(batches)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "_, params = vdm.init_with_output({\"sample\": rng, \"params\": rng}, x_batch[0], conditioning_batch[0], mask_batch[0])\n",
    "\n",
    "print(f\"Params: {param_count(params):,}\")\n",
    "\n",
    "# Training config and state\n",
    "schedule = optax.warmup_cosine_decay_schedule(init_value=0.0, peak_value=config.optim.learning_rate, warmup_steps=config.training.warmup_steps, decay_steps=config.training.n_train_steps)\n",
    "tx = optax.adamw(learning_rate=schedule, weight_decay=config.optim.weight_decay)\n",
    "if hasattr(config.optim, \"grad_clip\"):\n",
    "    if config.optim.grad_clip is not None:\n",
    "        tx = optax.chain(\n",
    "            optax.clip(config.optim.grad_clip),\n",
    "            tx,\n",
    "        )\n",
    "\n",
    "state = train_state.TrainState.create(apply_fn=vdm.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"{}/{}/\".format(logging_dir, run_name)  # Load SLURM run\n",
    "restored_state = checkpoints.restore_checkpoint(ckpt_dir=ckpt_dir, target=state, step=295000)\n",
    "\n",
    "if state is restored_state:\n",
    "    raise FileNotFoundError(f\"Did not load checkpoint correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x * norm_dict['std'] + norm_dict['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and evaluate simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2\n",
    "idx_rnd = vnp.random.choice(vnp.arange(len(x)), size=n_samples, replace=False)\n",
    "\n",
    "cond_gen = conditioning[idx_rnd]\n",
    "mask_gen = mask[idx_rnd]\n",
    "\n",
    "rng, _ = jax.random.split(rng)\n",
    "\n",
    "x_samples = generate(vdm, restored_state.params, rng, (n_samples, config.data.n_particles), conditioning=cond_gen, mask=mask_gen, steps=500)\n",
    "x_samples = x_samples.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = x_samples * norm_dict['std'] + norm_dict['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.906751 , 3.1594696, 1.3696197, ..., 3.113092 , 1.4599595,\n",
       "       1.2355965], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_array(arr, min_val, max_val):\n",
    "\n",
    "    # Find the minimum and maximum values of the input array\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "\n",
    "    # Scale the array\n",
    "    scaled_arr = (arr - arr_min) / (arr_max - arr_min) * (max_val - min_val) + min_val\n",
    "\n",
    "    return scaled_arr\n",
    "\n",
    "scale_array(np.exp(x_samples[idx, :, 6]), 1., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx_rnd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m idx_x \u001b[38;5;241m=\u001b[39m \u001b[43midx_rnd\u001b[49m[idx]\n\u001b[1;32m      4\u001b[0m color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirebrick\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m11\u001b[39m), subplot_kw\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprojection\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx_rnd' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "idx_x = idx_rnd[idx]\n",
    "\n",
    "color = \"firebrick\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 11), subplot_kw={'projection':'3d'})\n",
    "\n",
    "ax1.scatter(x_samples[idx, :, 0], x_samples[idx, :, 1], x_samples[idx, :, 2], \n",
    "            alpha=0.2, color=color,\n",
    "            s=scale_array(np.exp(x_samples[idx, :, 6]), 3., 90.));\n",
    "\n",
    "ax2.scatter(x[idx_x, :, 0], x[idx_x, :, 1], x[idx_x, :, 2], \n",
    "            alpha=0.2, color=color,\n",
    "            s=scale_array(np.exp(x[idx_x, :, 6]), 3., 90.));\n",
    "\n",
    "ax1.quiver(x_samples[idx, :, 0], x_samples[idx, :, 1], x_samples[idx, :, 2],\n",
    "           x_samples[idx, :, 3], x_samples[idx, :, 4], x_samples[idx, :, 5], \n",
    "           linewidths=1., length=0.08, color='grey', alpha=0.4,)\n",
    "\n",
    "ax2.quiver(x[idx_x, :, 0], x[idx_x, :, 1], x[idx_x, :, 2],\n",
    "           x[idx_x, :, 3], x[idx_x, :, 4], x[idx_x, :, 5], \n",
    "           linewidths=1., length=0.08, color='grey', alpha=0.4,)\n",
    "\n",
    "ax1.set_title(r\"\\textbf{Generated box}\", fontsize=28, rotation=36, y=0.77, x=0.22)\n",
    "ax2.set_title(r\"\\textbf{Simulated box}\", fontsize=28, rotation=36, y=0.77, x=0.22)\n",
    "\n",
    "lims = np.array([-20, 1020])\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_zlim(lims)\n",
    "\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "\n",
    "    ax.xaxis.pane.set_edgecolor('w')\n",
    "    ax.yaxis.pane.set_edgecolor('w')\n",
    "    ax.zaxis.pane.set_edgecolor('w')\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    box_color = 'k'\n",
    "    box_ls = '--'\n",
    "    box_alpha = 0.5\n",
    "    box_lw = 0.9\n",
    "    \n",
    "    r = np.array([0, 1000])\n",
    "    X, Y = np.meshgrid(r, r)\n",
    "    \n",
    "    # Re-creating the 2D arrays for Z component to match the shape of X and Y for the top and bottom surfaces\n",
    "    Z_bottom = np.zeros_like(X)\n",
    "    Z_top = np.ones_like(X) * Z[1]\n",
    "    \n",
    "    # Bottom surface\n",
    "    ax.plot_wireframe(X, Y, Z_bottom, alpha=box_alpha, lw=box_lw, color=box_color, ls=box_ls)\n",
    "    # Top surface\n",
    "    ax.plot_wireframe(X, Y, Z_top, alpha=box_alpha, lw=box_lw, color=box_color, ls=box_ls)\n",
    "    # Sides\n",
    "    ax.plot_wireframe(X, np.full_like(X, Z[0]), Y, alpha=box_alpha, lw=box_lw, color=box_color, ls=box_ls)\n",
    "    ax.plot_wireframe(X, np.full_like(X, Z[1]), Y, alpha=box_alpha, lw=box_lw, color=box_color, ls=box_ls)\n",
    "    ax.plot_wireframe(np.full_like(Y, Z[0]), Y, X, alpha=box_alpha, lw=box_lw, color=box_color, ls=box_ls)\n",
    "    ax.plot_wireframe(np.full_like(Y, Z[1]), Y, X, alpha=box_alpha, lw=box_lw, color=box_color, ls=box_ls)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"plots/box_vel_viz.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
